{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Etapa_Fasica\n",
       "Solitaria               840\n",
       "Trasciens Congregans     43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/2022.csv')\n",
    "data = data[data['Actividad_Realizada'] == 'Muestreo']\n",
    "data['Etapa_Fasica'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recomendaciones\n",
       "PEP6                                            49\n",
       "PEP 06                                          16\n",
       "SE APLICO CONTROL BIOLOGICO AEREO EN 50 HAS.     1\n",
       "SE APLICO CONTROL BIOLOGICO AEREO EN 77 HAS      1\n",
       "evaluacion de aplicacion con drone               1\n",
       "área quemada                                     1\n",
       "Àrea quemada                                     1\n",
       "àrea con aplicaciòn quìmica                      1\n",
       "evalucion de aplicacion con drone                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['Recomendaciones'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resultado\n",
       "Negativo      6631\n",
       "Positivo      1168\n",
       "En proceso      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/2023.csv')\n",
    "data = data[data['Actividad_Realizada'] == 'Exploración']\n",
    "data['Resultado'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resultado\n",
       "Negativo    6631\n",
       "Positivo    1168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(data[data['Resultado']=='En proceso'].index, inplace=True)\n",
    "data['Resultado'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\1378835331.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output['Fecha_inicio'] = data_output['Fecha'] - timedelta(days=96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Fecha_inicio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03 00:00:00</td>\n",
       "      <td>20.85595</td>\n",
       "      <td>-90.25643</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2022-09-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03 00:00:00</td>\n",
       "      <td>20.85498</td>\n",
       "      <td>-90.26168</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2022-09-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 00:00:00</td>\n",
       "      <td>20.81349</td>\n",
       "      <td>-90.19725</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2022-09-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-03 00:00:00</td>\n",
       "      <td>20.80072</td>\n",
       "      <td>-90.19945</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2022-09-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03 00:00:00</td>\n",
       "      <td>20.83347</td>\n",
       "      <td>-90.21466</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2022-09-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>2023-12-28 00:00:00</td>\n",
       "      <td>20.97265</td>\n",
       "      <td>-88.97319</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2023-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>2023-12-29 00:00:00</td>\n",
       "      <td>20.98016</td>\n",
       "      <td>-88.96617</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2023-09-24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>2023-12-29 00:00:00</td>\n",
       "      <td>20.95807</td>\n",
       "      <td>-88.89866</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2023-09-24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>2023-12-28 00:00:00</td>\n",
       "      <td>20.99703</td>\n",
       "      <td>-88.97471</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2023-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>2023-12-28 00:00:00</td>\n",
       "      <td>20.99062</td>\n",
       "      <td>-88.97449</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2023-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7799 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Fecha   Latitud  Longitud Resultado         Fecha_inicio\n",
       "0     2023-01-03 00:00:00  20.85595 -90.25643  Negativo  2022-09-29 00:00:00\n",
       "1     2023-01-03 00:00:00  20.85498 -90.26168  Negativo  2022-09-29 00:00:00\n",
       "2     2023-01-03 00:00:00  20.81349 -90.19725  Negativo  2022-09-29 00:00:00\n",
       "3     2023-01-03 00:00:00  20.80072 -90.19945  Negativo  2022-09-29 00:00:00\n",
       "4     2023-01-03 00:00:00  20.83347 -90.21466  Negativo  2022-09-29 00:00:00\n",
       "...                   ...       ...       ...       ...                  ...\n",
       "7974  2023-12-28 00:00:00  20.97265 -88.97319  Negativo  2023-09-23 00:00:00\n",
       "7975  2023-12-29 00:00:00  20.98016 -88.96617  Negativo  2023-09-24 00:00:00\n",
       "7976  2023-12-29 00:00:00  20.95807 -88.89866  Negativo  2023-09-24 00:00:00\n",
       "7977  2023-12-28 00:00:00  20.99703 -88.97471  Negativo  2023-09-23 00:00:00\n",
       "7978  2023-12-28 00:00:00  20.99062 -88.97449  Negativo  2023-09-23 00:00:00\n",
       "\n",
       "[7799 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output = data[['Fecha','Latitud','Longitud','Resultado']]\n",
    "data_output.loc[:,'Fecha'] = data_output['Fecha'].astype('datetime64[s]')\n",
    "\n",
    "data_output['Fecha_inicio'] = data_output['Fecha'] - timedelta(days=96)\n",
    "data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = pd.date_range('2021-09-20', '2021-09-20')\n",
    "\n",
    "def get_series(folder,field_name,row,names,xmin,xmax):\n",
    "    df = pd.read_csv(folder +field_name+'/' +  str(row['Latitud']) + '_' + str(row['Longitud']) + '.csv')\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')  \n",
    "    df = df.set_index('date').asfreq('D', method='ffill').reset_index()\n",
    "    \n",
    "    mask = (df['date'] > row['Fecha_inicio']) & (df['date'] <= row['Fecha'])\n",
    "    df = df.loc[mask]\n",
    "    df[names] = (df[names] - xmin )/(xmax-xmin)\n",
    "    list_f = df[names].values.tolist()\n",
    "    len_list = len(list_f)  \n",
    "    if len_list == 0:\n",
    "        list_f = [0]*96\n",
    "    if len_list != 96:\n",
    "        #print(len(list_f))\n",
    "        for i in range(len_list,96):\n",
    "            list_f.append(list_f[len_list-1])\n",
    "        #print(list_f)\n",
    "        \n",
    "        #print(len(list_f))\n",
    "        #print(row)\n",
    "\n",
    "    return list_f\n",
    "\n",
    "\n",
    "\n",
    "def get_series_group(folder,field_name,row,names,xmin,xmax):\n",
    "    df = pd.read_csv(folder +field_name+'/' +  str(row['Latitud']) + '_' + str(row['Longitud']) + '.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y%m%d')  \n",
    "    #df = df.set_index('date').asfreq('D', method='ffill').reset_index()\n",
    "    mask = (df['date'] > row['Fecha_inicio']) & (df['date'] <= row['Fecha'])\n",
    "    df = df.loc[mask]\n",
    "    list_f = df[names].values.tolist()  \n",
    "    len_list = len(list_f)  \n",
    "    if len_list == 0:\n",
    "        list_f = [0]*96\n",
    "        len_list = len(list_f)  \n",
    "    if len_list != 96:\n",
    "        print('len list')\n",
    "        print(len(list_f))\n",
    "        for i in range(len_list,96):\n",
    "            list_f.append(list_f[len_list-1])\n",
    "\n",
    "        print('len list f')\n",
    "        print(len(list_f))\n",
    "        #print(row)\n",
    "\n",
    "    return list_f\n",
    "\n",
    "#get_series(data_output.iloc[0])x['NDVI'].tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output['NDVI'] = data_output.apply(lambda row: get_series('gee-coordinates-2023/','NDVI',row,'NDVI',0,1), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LST_Day_1km\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output['LST_Day_1km'] = data_output.apply(lambda row: get_series('gee-coordinates-2023/','LST_Day_1km',row,'LST_Day_1km',0,1), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Psurf_f_inst', 'Qair_f_inst', 'Rainf_tavg', 'Tair_f_inst', 'Wind_f_inst', 'RootMoist_inst']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','SOIL',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','SOIL',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','SOIL',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','SOIL',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','SOIL',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','SOIL',row,feature,0,1), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prcp', 'srad', 'tmax', 'tmin', 'vp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','DAYMET_V4',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','DAYMET_V4',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','DAYMET_V4',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','DAYMET_V4',row,feature,0,1), axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_23280\\3532393074.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','DAYMET_V4',row,feature,0,1), axis=1)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('NDVI')\n",
    "data_output['NDVI'] = data_output.apply(lambda row: get_series('gee-coordinates-2023/','NDVI',row,'NDVI',0,1), axis=1)\n",
    "\n",
    "print('LST_Day_1km')\n",
    "data_output['LST_Day_1km'] = data_output.apply(lambda row: get_series('gee-coordinates-2023/','LST_Day_1km',row,'LST_Day_1km',0,1), axis=1)\n",
    "\n",
    "print(['Psurf_f_inst','Qair_f_inst','Rainf_tavg','Tair_f_inst','Wind_f_inst','RootMoist_inst'])\n",
    "features2 =  ['Psurf_f_inst','Qair_f_inst','Rainf_tavg','Tair_f_inst','Wind_f_inst','RootMoist_inst']\n",
    "for feature in features2:\n",
    "    data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','SOIL',row,feature,0,1), axis=1)\n",
    "\n",
    "print(['prcp','srad','tmax','tmin','vp'])\n",
    "features =  ['prcp','srad','tmax','tmin','vp']\n",
    "for feature in features:\n",
    "    data_output[feature] = data_output.apply(lambda row: get_series_group('gee-coordinates-2023/','DAYMET_V4',row,feature,0,1), axis=1)\n",
    "\n",
    "dataset = data_output[features+features2+['LST_Day_1km','NDVI','Resultado']]\n",
    "dataset.to_csv('data/2023-dataset.csv', index=False) \n",
    "#dataset.to_csv('data/2022-dataset.csv', index=False) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LST_Day_1km\n",
      "NDVI\n",
      "Psurf_f_inst\n",
      "Qair_f_inst\n",
      "Rainf_tavg\n",
      "Tair_f_inst\n",
      "Wind_f_inst\n",
      "RootMoist_inst\n",
      "prcp\n",
      "srad\n",
      "tmax\n",
      "tmin\n",
      "vp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/kxcs2s054c32h_5hwhhg4bd40000gn/T/ipykernel_45971/3348667295.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_4'] = dataset.apply(lambda row: convert(row,feature,36,48),axis=1)\n",
      "/var/folders/9n/kxcs2s054c32h_5hwhhg4bd40000gn/T/ipykernel_45971/3348667295.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_5'] = dataset.apply(lambda row: convert(row,feature,48,60),axis=1)\n",
      "/var/folders/9n/kxcs2s054c32h_5hwhhg4bd40000gn/T/ipykernel_45971/3348667295.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_6'] = dataset.apply(lambda row: convert(row,feature,60,72),axis=1)\n",
      "/var/folders/9n/kxcs2s054c32h_5hwhhg4bd40000gn/T/ipykernel_45971/3348667295.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_7'] = dataset.apply(lambda row: convert(row,feature,72,84),axis=1)\n",
      "/var/folders/9n/kxcs2s054c32h_5hwhhg4bd40000gn/T/ipykernel_45971/3348667295.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_8'] = dataset.apply(lambda row: convert(row,feature,84,96),axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LST_Day_1km_1</th>\n",
       "      <th>LST_Day_1km_2</th>\n",
       "      <th>LST_Day_1km_3</th>\n",
       "      <th>LST_Day_1km_4</th>\n",
       "      <th>LST_Day_1km_5</th>\n",
       "      <th>LST_Day_1km_6</th>\n",
       "      <th>LST_Day_1km_7</th>\n",
       "      <th>LST_Day_1km_8</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>tmin_7</th>\n",
       "      <th>tmin_8</th>\n",
       "      <th>vp_1</th>\n",
       "      <th>vp_2</th>\n",
       "      <th>vp_3</th>\n",
       "      <th>vp_4</th>\n",
       "      <th>vp_5</th>\n",
       "      <th>vp_6</th>\n",
       "      <th>vp_7</th>\n",
       "      <th>vp_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "      <td>7799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15255.213671</td>\n",
       "      <td>15254.206800</td>\n",
       "      <td>15250.388875</td>\n",
       "      <td>15253.502297</td>\n",
       "      <td>15258.535752</td>\n",
       "      <td>15258.239603</td>\n",
       "      <td>15253.777974</td>\n",
       "      <td>15252.833216</td>\n",
       "      <td>6613.497436</td>\n",
       "      <td>6634.931102</td>\n",
       "      <td>...</td>\n",
       "      <td>22.279376</td>\n",
       "      <td>22.319076</td>\n",
       "      <td>2097.534073</td>\n",
       "      <td>2142.753447</td>\n",
       "      <td>2189.859193</td>\n",
       "      <td>2224.726563</td>\n",
       "      <td>2242.686664</td>\n",
       "      <td>2239.486492</td>\n",
       "      <td>2206.773433</td>\n",
       "      <td>2173.042916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>210.915704</td>\n",
       "      <td>214.654367</td>\n",
       "      <td>216.510660</td>\n",
       "      <td>214.858517</td>\n",
       "      <td>207.683393</td>\n",
       "      <td>192.590453</td>\n",
       "      <td>179.731659</td>\n",
       "      <td>174.326298</td>\n",
       "      <td>1421.508590</td>\n",
       "      <td>1415.829049</td>\n",
       "      <td>...</td>\n",
       "      <td>2.266660</td>\n",
       "      <td>2.251899</td>\n",
       "      <td>655.833698</td>\n",
       "      <td>629.232122</td>\n",
       "      <td>585.235645</td>\n",
       "      <td>551.743151</td>\n",
       "      <td>540.376932</td>\n",
       "      <td>594.799377</td>\n",
       "      <td>666.555953</td>\n",
       "      <td>726.643837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14800.333333</td>\n",
       "      <td>14747.916667</td>\n",
       "      <td>14699.916667</td>\n",
       "      <td>14827.500000</td>\n",
       "      <td>14813.083333</td>\n",
       "      <td>14786.583333</td>\n",
       "      <td>14803.916667</td>\n",
       "      <td>14664.250000</td>\n",
       "      <td>1977.666667</td>\n",
       "      <td>1294.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.757500</td>\n",
       "      <td>16.783333</td>\n",
       "      <td>896.429164</td>\n",
       "      <td>894.070002</td>\n",
       "      <td>901.710002</td>\n",
       "      <td>956.823334</td>\n",
       "      <td>906.647502</td>\n",
       "      <td>888.688339</td>\n",
       "      <td>882.500839</td>\n",
       "      <td>897.375824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15056.000000</td>\n",
       "      <td>15055.166667</td>\n",
       "      <td>15052.333333</td>\n",
       "      <td>15057.916667</td>\n",
       "      <td>15079.875000</td>\n",
       "      <td>15107.583333</td>\n",
       "      <td>15117.833333</td>\n",
       "      <td>15129.500000</td>\n",
       "      <td>5480.333333</td>\n",
       "      <td>5493.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>20.137083</td>\n",
       "      <td>20.363333</td>\n",
       "      <td>1787.406657</td>\n",
       "      <td>1909.143326</td>\n",
       "      <td>1937.985835</td>\n",
       "      <td>1932.068746</td>\n",
       "      <td>1934.877914</td>\n",
       "      <td>1933.096252</td>\n",
       "      <td>1895.725408</td>\n",
       "      <td>1698.148336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15239.500000</td>\n",
       "      <td>15240.916667</td>\n",
       "      <td>15222.666667</td>\n",
       "      <td>15222.916667</td>\n",
       "      <td>15221.000000</td>\n",
       "      <td>15229.833333</td>\n",
       "      <td>15231.166667</td>\n",
       "      <td>15241.000000</td>\n",
       "      <td>6841.666667</td>\n",
       "      <td>6946.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>23.197500</td>\n",
       "      <td>23.208333</td>\n",
       "      <td>2190.267487</td>\n",
       "      <td>2223.169993</td>\n",
       "      <td>2220.601685</td>\n",
       "      <td>2214.755809</td>\n",
       "      <td>2232.556712</td>\n",
       "      <td>2253.450043</td>\n",
       "      <td>2281.454976</td>\n",
       "      <td>2325.236674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15424.500000</td>\n",
       "      <td>15430.875000</td>\n",
       "      <td>15434.166667</td>\n",
       "      <td>15434.250000</td>\n",
       "      <td>15428.500000</td>\n",
       "      <td>15393.875000</td>\n",
       "      <td>15378.208333</td>\n",
       "      <td>15366.791667</td>\n",
       "      <td>7800.000000</td>\n",
       "      <td>7787.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>24.255000</td>\n",
       "      <td>24.365417</td>\n",
       "      <td>2585.487096</td>\n",
       "      <td>2600.089152</td>\n",
       "      <td>2609.442922</td>\n",
       "      <td>2623.179159</td>\n",
       "      <td>2636.783335</td>\n",
       "      <td>2686.196248</td>\n",
       "      <td>2727.860819</td>\n",
       "      <td>2849.303772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15889.333333</td>\n",
       "      <td>15866.583333</td>\n",
       "      <td>15876.333333</td>\n",
       "      <td>15843.500000</td>\n",
       "      <td>15870.750000</td>\n",
       "      <td>15851.083333</td>\n",
       "      <td>15834.250000</td>\n",
       "      <td>15816.500000</td>\n",
       "      <td>9799.833333</td>\n",
       "      <td>9717.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.385000</td>\n",
       "      <td>25.409167</td>\n",
       "      <td>3228.960815</td>\n",
       "      <td>3178.584167</td>\n",
       "      <td>3191.529175</td>\n",
       "      <td>3203.571696</td>\n",
       "      <td>3193.013306</td>\n",
       "      <td>3194.997498</td>\n",
       "      <td>3206.190002</td>\n",
       "      <td>3208.705831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LST_Day_1km_1  LST_Day_1km_2  LST_Day_1km_3  LST_Day_1km_4  \\\n",
       "count    7799.000000    7799.000000    7799.000000    7799.000000   \n",
       "mean    15255.213671   15254.206800   15250.388875   15253.502297   \n",
       "std       210.915704     214.654367     216.510660     214.858517   \n",
       "min     14800.333333   14747.916667   14699.916667   14827.500000   \n",
       "25%     15056.000000   15055.166667   15052.333333   15057.916667   \n",
       "50%     15239.500000   15240.916667   15222.666667   15222.916667   \n",
       "75%     15424.500000   15430.875000   15434.166667   15434.250000   \n",
       "max     15889.333333   15866.583333   15876.333333   15843.500000   \n",
       "\n",
       "       LST_Day_1km_5  LST_Day_1km_6  LST_Day_1km_7  LST_Day_1km_8  \\\n",
       "count    7799.000000    7799.000000    7799.000000    7799.000000   \n",
       "mean    15258.535752   15258.239603   15253.777974   15252.833216   \n",
       "std       207.683393     192.590453     179.731659     174.326298   \n",
       "min     14813.083333   14786.583333   14803.916667   14664.250000   \n",
       "25%     15079.875000   15107.583333   15117.833333   15129.500000   \n",
       "50%     15221.000000   15229.833333   15231.166667   15241.000000   \n",
       "75%     15428.500000   15393.875000   15378.208333   15366.791667   \n",
       "max     15870.750000   15851.083333   15834.250000   15816.500000   \n",
       "\n",
       "            NDVI_1       NDVI_2  ...       tmin_7       tmin_8         vp_1  \\\n",
       "count  7799.000000  7799.000000  ...  7799.000000  7799.000000  7799.000000   \n",
       "mean   6613.497436  6634.931102  ...    22.279376    22.319076  2097.534073   \n",
       "std    1421.508590  1415.829049  ...     2.266660     2.251899   655.833698   \n",
       "min    1977.666667  1294.000000  ...    16.757500    16.783333   896.429164   \n",
       "25%    5480.333333  5493.041667  ...    20.137083    20.363333  1787.406657   \n",
       "50%    6841.666667  6946.333333  ...    23.197500    23.208333  2190.267487   \n",
       "75%    7800.000000  7787.333333  ...    24.255000    24.365417  2585.487096   \n",
       "max    9799.833333  9717.000000  ...    25.385000    25.409167  3228.960815   \n",
       "\n",
       "              vp_2         vp_3         vp_4         vp_5         vp_6  \\\n",
       "count  7799.000000  7799.000000  7799.000000  7799.000000  7799.000000   \n",
       "mean   2142.753447  2189.859193  2224.726563  2242.686664  2239.486492   \n",
       "std     629.232122   585.235645   551.743151   540.376932   594.799377   \n",
       "min     894.070002   901.710002   956.823334   906.647502   888.688339   \n",
       "25%    1909.143326  1937.985835  1932.068746  1934.877914  1933.096252   \n",
       "50%    2223.169993  2220.601685  2214.755809  2232.556712  2253.450043   \n",
       "75%    2600.089152  2609.442922  2623.179159  2636.783335  2686.196248   \n",
       "max    3178.584167  3191.529175  3203.571696  3193.013306  3194.997498   \n",
       "\n",
       "              vp_7         vp_8  \n",
       "count  7799.000000  7799.000000  \n",
       "mean   2206.773433  2173.042916  \n",
       "std     666.555953   726.643837  \n",
       "min     882.500839   897.375824  \n",
       "25%    1895.725408  1698.148336  \n",
       "50%    2281.454976  2325.236674  \n",
       "75%    2727.860819  2849.303772  \n",
       "max    3206.190002  3208.705831  \n",
       "\n",
       "[8 rows x 104 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv('data/2023-dataset.csv')\n",
    "\n",
    "features_all = ['LST_Day_1km','NDVI']+['Psurf_f_inst','Qair_f_inst','Rainf_tavg','Tair_f_inst','Wind_f_inst','RootMoist_inst']+['prcp','srad','tmax','tmin','vp']\n",
    "\n",
    "\n",
    "\n",
    "#dataset = data_output[['Resultado']+features+features2]\n",
    "\n",
    "def convert(row,feature,st,end):\n",
    "    list_parsed = eval(row[feature])[st:end]\n",
    "    if np.sum(list_parsed) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.mean(list_parsed)\n",
    "\n",
    "feature_dataset = pd.DataFrame()\n",
    "feature_dataset['Resultado'] = dataset['Resultado']\n",
    "for feature in features_all:\n",
    "    print(feature)\n",
    "    feature_dataset[feature + '_1'] = dataset.apply(lambda row: convert(row,feature,0,12),axis=1)\n",
    "    feature_dataset[feature + '_2'] = dataset.apply(lambda row: convert(row,feature,12,24),axis=1)\n",
    "    feature_dataset[feature + '_3'] = dataset.apply(lambda row: convert(row,feature,24,36),axis=1)\n",
    "    feature_dataset[feature + '_4'] = dataset.apply(lambda row: convert(row,feature,36,48),axis=1)\n",
    "    feature_dataset[feature + '_5'] = dataset.apply(lambda row: convert(row,feature,48,60),axis=1)\n",
    "    feature_dataset[feature + '_6'] = dataset.apply(lambda row: convert(row,feature,60,72),axis=1)\n",
    "    feature_dataset[feature + '_7'] = dataset.apply(lambda row: convert(row,feature,72,84),axis=1)\n",
    "    feature_dataset[feature + '_8'] = dataset.apply(lambda row: convert(row,feature,84,96),axis=1)\n",
    "\n",
    "feature_dataset.to_csv('data/2023-feature-dataset.csv', index=False) \n",
    "feature_dataset.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
