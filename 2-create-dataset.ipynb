{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2024\n",
    "fecha = datetime.strptime(f'{year}-01-01', '%Y-%m-%d')\n",
    "fecha_inicio = fecha - timedelta(days=96)\n",
    "fecha_fin = datetime.strptime(f'{year+1}-01-01', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'data/{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Etapa_Fasica\n",
       "Trasciens Congregans    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['Actividad_Realizada'] == 'Exploración']\n",
    "data['Etapa_Fasica'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resultado\n",
       "Negativo    4902\n",
       "Positivo     660\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['Resultado'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resultado\n",
       "Positivo    1780\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(data[data['Resultado']=='En proceso'].index, inplace=True)\n",
    "data['Resultado'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\913995912.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output.loc[:,'Fecha_fin'] = data_output['Fecha']\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\913995912.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output.loc[:,'Fecha_inicio'] = data_output['Fecha'] - timedelta(days=96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Latitud</th>\n",
       "      <th>Longitud</th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Fecha_fin</th>\n",
       "      <th>Fecha_inicio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>20.87519</td>\n",
       "      <td>-89.19463</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>2023-09-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>20.88422</td>\n",
       "      <td>-89.34875</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>2023-09-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03 00:00:00</td>\n",
       "      <td>20.86403</td>\n",
       "      <td>-89.33215</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2024-01-03 00:00:00</td>\n",
       "      <td>2023-09-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>20.89794</td>\n",
       "      <td>-89.43314</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>2023-09-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>20.83351</td>\n",
       "      <td>-89.30793</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>2023-09-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>21.14855</td>\n",
       "      <td>-88.85028</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>21.14259</td>\n",
       "      <td>-88.88364</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>21.12988</td>\n",
       "      <td>-88.87181</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>21.12769</td>\n",
       "      <td>-88.85572</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>21.13761</td>\n",
       "      <td>-88.82186</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>2024-09-26 00:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5562 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Fecha   Latitud  Longitud Resultado            Fecha_fin  \\\n",
       "0     2024-01-02 00:00:00  20.87519 -89.19463  Negativo  2024-01-02 00:00:00   \n",
       "1     2024-01-02 00:00:00  20.88422 -89.34875  Negativo  2024-01-02 00:00:00   \n",
       "2     2024-01-03 00:00:00  20.86403 -89.33215  Negativo  2024-01-03 00:00:00   \n",
       "3     2024-01-02 00:00:00  20.89794 -89.43314  Negativo  2024-01-02 00:00:00   \n",
       "4     2024-01-02 00:00:00  20.83351 -89.30793  Negativo  2024-01-02 00:00:00   \n",
       "...                   ...       ...       ...       ...                  ...   \n",
       "6216  2024-09-26 00:00:00  21.14855 -88.85028  Negativo  2024-09-26 00:00:00   \n",
       "6217  2024-09-26 00:00:00  21.14259 -88.88364  Negativo  2024-09-26 00:00:00   \n",
       "6218  2024-09-26 00:00:00  21.12988 -88.87181  Negativo  2024-09-26 00:00:00   \n",
       "6219  2024-09-26 00:00:00  21.12769 -88.85572  Positivo  2024-09-26 00:00:00   \n",
       "6222  2024-09-26 00:00:00  21.13761 -88.82186  Positivo  2024-09-26 00:00:00   \n",
       "\n",
       "             Fecha_inicio  \n",
       "0     2023-09-28 00:00:00  \n",
       "1     2023-09-28 00:00:00  \n",
       "2     2023-09-29 00:00:00  \n",
       "3     2023-09-28 00:00:00  \n",
       "4     2023-09-28 00:00:00  \n",
       "...                   ...  \n",
       "6216  2024-06-22 00:00:00  \n",
       "6217  2024-06-22 00:00:00  \n",
       "6218  2024-06-22 00:00:00  \n",
       "6219  2024-06-22 00:00:00  \n",
       "6222  2024-06-22 00:00:00  \n",
       "\n",
       "[5562 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output = data[['Fecha','Latitud','Longitud','Resultado']]\n",
    "data_output.loc[:,'Fecha'] = data_output['Fecha'].astype('datetime64[s]')\n",
    "data_output.loc[:,'Fecha_fin'] = data_output['Fecha']\n",
    "data_output.loc[:,'Fecha_inicio'] = data_output['Fecha'] - timedelta(days=96)\n",
    "data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_series(folder,field_name,row,names):\n",
    "    df = pd.read_csv(folder +field_name+'/' +  str(row['Latitud']) + '_' + str(row['Longitud']) + '.csv')\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')  \n",
    "    df = df.set_index('date').asfreq('D', method='ffill').reset_index()\n",
    "    \n",
    "    mask = (df['date'] > row['Fecha_inicio']) & (df['date'] <= row['Fecha'])\n",
    "    df = df.loc[mask]\n",
    "    list_f = df[names].values.tolist()\n",
    "    len_list = len(list_f)  \n",
    "    if len_list == 0:\n",
    "        list_f = [0]*96\n",
    "    if len_list != 96:\n",
    "        #print(len(list_f))\n",
    "        for i in range(len_list,96):\n",
    "            list_f.append(list_f[len_list-1])\n",
    "        #print(list_f)\n",
    "        \n",
    "        #print(len(list_f))\n",
    "        #print(row)\n",
    "\n",
    "    return list_f\n",
    "\n",
    "\n",
    "\n",
    "def get_series_group(folder,field_name,row,names):\n",
    "    df = pd.read_csv(folder +field_name+'/' +  str(row['Latitud']) + '_' + str(row['Longitud']) + '.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y%m%d')  \n",
    "    #df = df.set_index('date').asfreq('D', method='ffill').reset_index()\n",
    "    mask = (df['date'] > row['Fecha_inicio']) & (df['date'] <= row['Fecha'])\n",
    "    df = df.loc[mask]\n",
    "    list_f = df[names].values.tolist()  \n",
    "    len_list = len(list_f)  \n",
    "    if len_list == 0:\n",
    "        list_f = [0]*96\n",
    "        len_list = len(list_f)  \n",
    "    if len_list != 96:\n",
    "        print('len list')\n",
    "        print(len(list_f))\n",
    "        for i in range(len_list,96):\n",
    "            list_f.append(list_f[len_list-1])\n",
    "\n",
    "        print('len list f')\n",
    "        print(len(list_f))\n",
    "        #print(row)\n",
    "\n",
    "    return list_f\n",
    "\n",
    "#get_series(data_output.iloc[0])x['NDVI'].tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series(folder,source,variable,row):\n",
    "    \n",
    "    df = pd.read_csv(folder + source +'/' +  str(row['Latitud']) + '_' + str(row['Longitud']) + '.csv')\n",
    "        \n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')  \n",
    "    \n",
    "    df = df.set_index('date').asfreq('D', method='ffill').reset_index()\n",
    "        \n",
    "    mask = (df['date'] > row['Fecha_inicio']) & (df['date'] <= row['Fecha'])\n",
    "    df = df.loc[mask]\n",
    "    list_f = df[variable].values.tolist()\n",
    "    len_list = len(list_f)  \n",
    "    if len_list == 0:\n",
    "        return [0]*96\n",
    "    if len_list != 96:\n",
    "        #print(variable)\n",
    "        #print(len_list)\n",
    "        for i in range(len_list,96):\n",
    "            list_f.append(list_f[len_list-1])\n",
    "\n",
    "    return list_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output['NDVI'] = data_output.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LST_Day_1km\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output['LST_Day_1km'] = data_output.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYMET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3457276416.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_output[feature] = data_output.apply(\n"
     ]
    }
   ],
   "source": [
    "print('NDVI')\n",
    "data_output['NDVI'] = data_output.apply(\n",
    "    lambda row: get_series(f'gee-coordinates-{year}/', \\\n",
    "    'NDVI', 'NDVI',row), axis=1)\n",
    "\n",
    "print('LST_Day_1km')\n",
    "data_output['LST_Day_1km'] = data_output.apply(\n",
    "    lambda row: get_series(f'gee-coordinates-{year}/',\n",
    "    'LST_Day_1km','LST_Day_1km',row), axis=1)\n",
    "\n",
    "print('SOIL')\n",
    "features2 =  ['Psurf_f_inst','Qair_f_inst','Rainf_tavg','Tair_f_inst','Wind_f_inst','RootMoist_inst']\n",
    "for feature in features2:\n",
    "    data_output[feature] = data_output.apply(\n",
    "        lambda row: get_series(f'gee-coordinates-{year}/', \\\n",
    "        'SOIL',feature,row), axis=1)\n",
    "\n",
    "print('DAYMET')\n",
    "features =  ['prcp','srad','tmax','tmin','vp']\n",
    "for feature in features:\n",
    "    data_output[feature] = data_output.apply(\n",
    "            lambda row: get_series(f'gee-coordinates-{year}/',\\\n",
    "            'DAYMET_V4',feature,row), axis=1)\n",
    "\n",
    "dataset = data_output[features+features2+['LST_Day_1km','NDVI','Resultado']]\n",
    "dataset.to_csv(f'data/{year}-dataset.csv', index=False) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LST_Day_1km\n",
      "NDVI\n",
      "Psurf_f_inst\n",
      "Qair_f_inst\n",
      "Rainf_tavg\n",
      "Tair_f_inst\n",
      "Wind_f_inst\n",
      "RootMoist_inst\n",
      "prcp\n",
      "srad\n",
      "tmax\n",
      "tmin\n",
      "vp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3072436313.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_4'] = dataset.apply(lambda row: convert(row,feature,36,48),axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3072436313.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_5'] = dataset.apply(lambda row: convert(row,feature,48,60),axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3072436313.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_6'] = dataset.apply(lambda row: convert(row,feature,60,72),axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3072436313.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_7'] = dataset.apply(lambda row: convert(row,feature,72,84),axis=1)\n",
      "C:\\Users\\seder\\AppData\\Local\\Temp\\ipykernel_32944\\3072436313.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_dataset[feature + '_8'] = dataset.apply(lambda row: convert(row,feature,84,96),axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LST_Day_1km_1</th>\n",
       "      <th>LST_Day_1km_2</th>\n",
       "      <th>LST_Day_1km_3</th>\n",
       "      <th>LST_Day_1km_4</th>\n",
       "      <th>LST_Day_1km_5</th>\n",
       "      <th>LST_Day_1km_6</th>\n",
       "      <th>LST_Day_1km_7</th>\n",
       "      <th>LST_Day_1km_8</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>tmin_7</th>\n",
       "      <th>tmin_8</th>\n",
       "      <th>vp_1</th>\n",
       "      <th>vp_2</th>\n",
       "      <th>vp_3</th>\n",
       "      <th>vp_4</th>\n",
       "      <th>vp_5</th>\n",
       "      <th>vp_6</th>\n",
       "      <th>vp_7</th>\n",
       "      <th>vp_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "      <td>5562.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15425.071152</td>\n",
       "      <td>15442.229714</td>\n",
       "      <td>15442.576651</td>\n",
       "      <td>15432.429357</td>\n",
       "      <td>15406.801555</td>\n",
       "      <td>15370.040603</td>\n",
       "      <td>15327.218282</td>\n",
       "      <td>15295.069325</td>\n",
       "      <td>4981.303788</td>\n",
       "      <td>4921.394043</td>\n",
       "      <td>...</td>\n",
       "      <td>2.284417</td>\n",
       "      <td>2.172369</td>\n",
       "      <td>402.794478</td>\n",
       "      <td>378.719743</td>\n",
       "      <td>353.274926</td>\n",
       "      <td>324.143148</td>\n",
       "      <td>299.562812</td>\n",
       "      <td>281.030802</td>\n",
       "      <td>261.921993</td>\n",
       "      <td>248.280704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>245.542203</td>\n",
       "      <td>250.783846</td>\n",
       "      <td>262.334645</td>\n",
       "      <td>274.106251</td>\n",
       "      <td>285.971512</td>\n",
       "      <td>290.070657</td>\n",
       "      <td>295.861661</td>\n",
       "      <td>280.097568</td>\n",
       "      <td>1453.534421</td>\n",
       "      <td>1470.700826</td>\n",
       "      <td>...</td>\n",
       "      <td>5.428324</td>\n",
       "      <td>5.130039</td>\n",
       "      <td>952.067433</td>\n",
       "      <td>895.767899</td>\n",
       "      <td>842.720048</td>\n",
       "      <td>780.148717</td>\n",
       "      <td>723.877335</td>\n",
       "      <td>675.863342</td>\n",
       "      <td>623.034070</td>\n",
       "      <td>586.420003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14693.500000</td>\n",
       "      <td>14730.750000</td>\n",
       "      <td>14651.083333</td>\n",
       "      <td>14715.000000</td>\n",
       "      <td>14529.000000</td>\n",
       "      <td>14656.916667</td>\n",
       "      <td>14686.166667</td>\n",
       "      <td>14602.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15205.937500</td>\n",
       "      <td>15253.208333</td>\n",
       "      <td>15255.291667</td>\n",
       "      <td>15176.000000</td>\n",
       "      <td>15121.166667</td>\n",
       "      <td>15098.020833</td>\n",
       "      <td>15079.333333</td>\n",
       "      <td>15080.270833</td>\n",
       "      <td>3905.791667</td>\n",
       "      <td>3852.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15461.625000</td>\n",
       "      <td>15493.208333</td>\n",
       "      <td>15499.000000</td>\n",
       "      <td>15508.208333</td>\n",
       "      <td>15491.000000</td>\n",
       "      <td>15379.625000</td>\n",
       "      <td>15207.000000</td>\n",
       "      <td>15173.875000</td>\n",
       "      <td>4555.916667</td>\n",
       "      <td>4495.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15629.083333</td>\n",
       "      <td>15637.645833</td>\n",
       "      <td>15639.375000</td>\n",
       "      <td>15649.625000</td>\n",
       "      <td>15643.166667</td>\n",
       "      <td>15634.083333</td>\n",
       "      <td>15620.812500</td>\n",
       "      <td>15571.770833</td>\n",
       "      <td>5871.500000</td>\n",
       "      <td>5782.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16048.000000</td>\n",
       "      <td>16069.000000</td>\n",
       "      <td>16019.250000</td>\n",
       "      <td>16025.000000</td>\n",
       "      <td>15995.333333</td>\n",
       "      <td>16005.416667</td>\n",
       "      <td>16069.000000</td>\n",
       "      <td>16050.000000</td>\n",
       "      <td>9618.166667</td>\n",
       "      <td>9245.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.534167</td>\n",
       "      <td>17.181667</td>\n",
       "      <td>3141.131653</td>\n",
       "      <td>2729.066691</td>\n",
       "      <td>2712.692505</td>\n",
       "      <td>2692.682495</td>\n",
       "      <td>2612.358358</td>\n",
       "      <td>2524.710042</td>\n",
       "      <td>2288.444173</td>\n",
       "      <td>1975.942505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LST_Day_1km_1  LST_Day_1km_2  LST_Day_1km_3  LST_Day_1km_4  \\\n",
       "count    5562.000000    5562.000000    5562.000000    5562.000000   \n",
       "mean    15425.071152   15442.229714   15442.576651   15432.429357   \n",
       "std       245.542203     250.783846     262.334645     274.106251   \n",
       "min     14693.500000   14730.750000   14651.083333   14715.000000   \n",
       "25%     15205.937500   15253.208333   15255.291667   15176.000000   \n",
       "50%     15461.625000   15493.208333   15499.000000   15508.208333   \n",
       "75%     15629.083333   15637.645833   15639.375000   15649.625000   \n",
       "max     16048.000000   16069.000000   16019.250000   16025.000000   \n",
       "\n",
       "       LST_Day_1km_5  LST_Day_1km_6  LST_Day_1km_7  LST_Day_1km_8  \\\n",
       "count    5562.000000    5562.000000    5562.000000    5562.000000   \n",
       "mean    15406.801555   15370.040603   15327.218282   15295.069325   \n",
       "std       285.971512     290.070657     295.861661     280.097568   \n",
       "min     14529.000000   14656.916667   14686.166667   14602.000000   \n",
       "25%     15121.166667   15098.020833   15079.333333   15080.270833   \n",
       "50%     15491.000000   15379.625000   15207.000000   15173.875000   \n",
       "75%     15643.166667   15634.083333   15620.812500   15571.770833   \n",
       "max     15995.333333   16005.416667   16069.000000   16050.000000   \n",
       "\n",
       "            NDVI_1       NDVI_2  ...       tmin_7       tmin_8         vp_1  \\\n",
       "count  5562.000000  5562.000000  ...  5562.000000  5562.000000  5562.000000   \n",
       "mean   4981.303788  4921.394043  ...     2.284417     2.172369   402.794478   \n",
       "std    1453.534421  1470.700826  ...     5.428324     5.130039   952.067433   \n",
       "min     313.000000    74.000000  ...     0.000000     0.000000     0.000000   \n",
       "25%    3905.791667  3852.000000  ...     0.000000     0.000000     0.000000   \n",
       "50%    4555.916667  4495.000000  ...     0.000000     0.000000     0.000000   \n",
       "75%    5871.500000  5782.375000  ...     0.000000     0.000000     0.000000   \n",
       "max    9618.166667  9245.000000  ...    19.534167    17.181667  3141.131653   \n",
       "\n",
       "              vp_2         vp_3         vp_4         vp_5         vp_6  \\\n",
       "count  5562.000000  5562.000000  5562.000000  5562.000000  5562.000000   \n",
       "mean    378.719743   353.274926   324.143148   299.562812   281.030802   \n",
       "std     895.767899   842.720048   780.148717   723.877335   675.863342   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max    2729.066691  2712.692505  2692.682495  2612.358358  2524.710042   \n",
       "\n",
       "              vp_7         vp_8  \n",
       "count  5562.000000  5562.000000  \n",
       "mean    261.921993   248.280704  \n",
       "std     623.034070   586.420003  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     0.000000  \n",
       "max    2288.444173  1975.942505  \n",
       "\n",
       "[8 rows x 104 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv(f'data/{year}-dataset.csv')\n",
    "\n",
    "features_all = ['LST_Day_1km','NDVI', \\\n",
    "                'Psurf_f_inst','Qair_f_inst','Rainf_tavg','Tair_f_inst','Wind_f_inst','RootMoist_inst', \\\n",
    "                    'prcp','srad','tmax','tmin','vp']\n",
    "\n",
    "def convert(row,feature,st,end):\n",
    "    list_parsed = eval(row[feature])[st:end]\n",
    "    if np.sum(list_parsed) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.mean(list_parsed)\n",
    "\n",
    "feature_dataset = pd.DataFrame()\n",
    "feature_dataset['Resultado'] = dataset['Resultado']\n",
    "for feature in features_all:\n",
    "    print(feature)\n",
    "    feature_dataset[feature + '_1'] = dataset.apply(lambda row: convert(row,feature,0,12),axis=1)\n",
    "    feature_dataset[feature + '_2'] = dataset.apply(lambda row: convert(row,feature,12,24),axis=1)\n",
    "    feature_dataset[feature + '_3'] = dataset.apply(lambda row: convert(row,feature,24,36),axis=1)\n",
    "    feature_dataset[feature + '_4'] = dataset.apply(lambda row: convert(row,feature,36,48),axis=1)\n",
    "    feature_dataset[feature + '_5'] = dataset.apply(lambda row: convert(row,feature,48,60),axis=1)\n",
    "    feature_dataset[feature + '_6'] = dataset.apply(lambda row: convert(row,feature,60,72),axis=1)\n",
    "    feature_dataset[feature + '_7'] = dataset.apply(lambda row: convert(row,feature,72,84),axis=1)\n",
    "    feature_dataset[feature + '_8'] = dataset.apply(lambda row: convert(row,feature,84,96),axis=1)\n",
    "\n",
    "feature_dataset.to_csv(f'data/{year}-feature-dataset.csv', index=False) \n",
    "feature_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/2021-feature-dataset.csv') \n",
    "df = df.query(\"Resultado != 'En proceso'\")\n",
    "df.to_csv(f'data/2021-feature-dataset.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
