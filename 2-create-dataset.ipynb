{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "fecha = datetime.strptime(f'{year}-01-01', '%Y-%m-%d')\n",
    "fecha_inicio = fecha - timedelta(days=96)\n",
    "fecha_fin = datetime.strptime(f'{year+1}-01-01', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'data/{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Etapa_Fasica\n",
       "Solitaria               840\n",
       "Trasciens Congregans     43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['Actividad_Realizada'] == 'Muestreo']\n",
    "data['Etapa_Fasica'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recomendaciones\n",
       "PEP6                                            49\n",
       "PEP 06                                          16\n",
       "SE APLICO CONTROL BIOLOGICO AEREO EN 50 HAS.     1\n",
       "SE APLICO CONTROL BIOLOGICO AEREO EN 77 HAS      1\n",
       "evaluacion de aplicacion con drone               1\n",
       "área quemada                                     1\n",
       "Àrea quemada                                     1\n",
       "àrea con aplicaciòn quìmica                      1\n",
       "evalucion de aplicacion con drone                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['Recomendaciones'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resultado\n",
       "Negativo    390\n",
       "Positivo     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(data[data['Resultado']=='En proceso'].index, inplace=True)\n",
    "data['Resultado'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = data[['Fecha','Latitud','Longitud','Resultado']]\n",
    "data_output.loc[:,'Fecha_fin'] = data_output['Fecha'].strftime('%Y-%m-%d').astype('datetime64[s]')\n",
    "data_output.loc[:,'Fecha_inicio'] = data_output['Fecha'] - timedelta(days=96)\n",
    "data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_series(folder,field_name,row,names):\n",
    "    df = pd.read_csv(folder +field_name+'/' +  str(row['Latitud']) + '_' + str(row['Longitud']) + '.csv')\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')  \n",
    "    df = df.set_index('date').asfreq('D', method='ffill').reset_index()\n",
    "    \n",
    "    mask = (df['date'] > row['Fecha_inicio']) & (df['date'] <= row['Fecha'])\n",
    "    df = df.loc[mask]\n",
    "    list_f = df[names].values.tolist()\n",
    "    len_list = len(list_f)  \n",
    "    if len_list == 0:\n",
    "        list_f = [0]*96\n",
    "    if len_list != 96:\n",
    "        #print(len(list_f))\n",
    "        for i in range(len_list,96):\n",
    "            list_f.append(list_f[len_list-1])\n",
    "        #print(list_f)\n",
    "        \n",
    "        #print(len(list_f))\n",
    "        #print(row)\n",
    "\n",
    "    return list_f\n",
    "\n",
    "\n",
    "\n",
    "def get_series_group(folder,field_name,row,names):\n",
    "    df = pd.read_csv(folder +field_name+'/' +  str(row['Latitud']) + '_' + str(row['Longitud']) + '.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y%m%d')  \n",
    "    #df = df.set_index('date').asfreq('D', method='ffill').reset_index()\n",
    "    mask = (df['date'] > row['Fecha_inicio']) & (df['date'] <= row['Fecha'])\n",
    "    df = df.loc[mask]\n",
    "    list_f = df[names].values.tolist()  \n",
    "    len_list = len(list_f)  \n",
    "    if len_list == 0:\n",
    "        list_f = [0]*96\n",
    "        len_list = len(list_f)  \n",
    "    if len_list != 96:\n",
    "        print('len list')\n",
    "        print(len(list_f))\n",
    "        for i in range(len_list,96):\n",
    "            list_f.append(list_f[len_list-1])\n",
    "\n",
    "        print('len list f')\n",
    "        print(len(list_f))\n",
    "        #print(row)\n",
    "\n",
    "    return list_f\n",
    "\n",
    "#get_series(data_output.iloc[0])x['NDVI'].tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NDVI')\n",
    "data_output['NDVI'] = data_output.apply(\n",
    "    lambda row: get_series(f'gee-coordinates-{year}/', \\\n",
    "    'NDVI',row,'NDVI'), axis=1)\n",
    "\n",
    "print('LST_Day_1km')\n",
    "data_output['LST_Day_1km'] = data_output.apply(\n",
    "    lambda row: get_series(f'gee-coordinates-{year}/',\n",
    "    'LST_Day_1km',row,'LST_Day_1km'), axis=1)\n",
    "\n",
    "print('SOIL')\n",
    "features2 =  ['Psurf_f_inst','Qair_f_inst','Rainf_tavg','Tair_f_inst','Wind_f_inst','RootMoist_inst']\n",
    "for feature in features2:\n",
    "    data_output[feature] = data_output.apply(\n",
    "        lambda row: get_series_group(f'gee-coordinates-{year}/', \\\n",
    "        'SOIL',row,feature), axis=1)\n",
    "\n",
    "print('DAYMET')\n",
    "features =  ['prcp','srad','tmax','tmin','vp']\n",
    "for feature in features:\n",
    "    data_output[feature] = data_output.apply(\n",
    "            lambda row: get_series_group(f'gee-coordinates-{year}/',\\\n",
    "            'DAYMET_V4',row,feature), axis=1)\n",
    "\n",
    "dataset = data_output[features+features2+['LST_Day_1km','NDVI','Resultado']]\n",
    "dataset.to_csv('data/{year}-dataset.csv', index=False) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.read_csv('data/{year}-dataset.csv')\n",
    "\n",
    "features_all = ['LST_Day_1km','NDVI', \\\n",
    "                'Psurf_f_inst','Qair_f_inst','Rainf_tavg','Tair_f_inst','Wind_f_inst','RootMoist_inst', \\\n",
    "                    'prcp','srad','tmax','tmin','vp']\n",
    "\n",
    "def convert(row,feature,st,end):\n",
    "    list_parsed = eval(row[feature])[st:end]\n",
    "    if np.sum(list_parsed) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.mean(list_parsed)\n",
    "\n",
    "feature_dataset = pd.DataFrame()\n",
    "feature_dataset['Resultado'] = dataset['Resultado']\n",
    "for feature in features_all:\n",
    "    print(feature)\n",
    "    feature_dataset[feature + '_1'] = dataset.apply(lambda row: convert(row,feature,0,12),axis=1)\n",
    "    feature_dataset[feature + '_2'] = dataset.apply(lambda row: convert(row,feature,12,24),axis=1)\n",
    "    feature_dataset[feature + '_3'] = dataset.apply(lambda row: convert(row,feature,24,36),axis=1)\n",
    "    feature_dataset[feature + '_4'] = dataset.apply(lambda row: convert(row,feature,36,48),axis=1)\n",
    "    feature_dataset[feature + '_5'] = dataset.apply(lambda row: convert(row,feature,48,60),axis=1)\n",
    "    feature_dataset[feature + '_6'] = dataset.apply(lambda row: convert(row,feature,60,72),axis=1)\n",
    "    feature_dataset[feature + '_7'] = dataset.apply(lambda row: convert(row,feature,72,84),axis=1)\n",
    "    feature_dataset[feature + '_8'] = dataset.apply(lambda row: convert(row,feature,84,96),axis=1)\n",
    "\n",
    "feature_dataset.to_csv('data/{year}-feature-dataset.csv', index=False) \n",
    "feature_dataset.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
